public class MemcachedConnection extends SpyThread { private static final int DOUBLE_CHECK_EMPTY = 256; private static final int EXCESSIVE_EMPTY = 0x1000000; private static final int DEFAULT_WAKEUP_DELAY = 1000; private static final int DEFAULT_RETRY_QUEUE_SIZE = -1; private static final int MAX_CLONE_COUNT = 100; private static final String RECON_QUEUE_METRIC = "[MEM] Reconnecting Nodes (ReconnectQueue)"; private static final String SHUTD_QUEUE_METRIC = "[MEM] Shutting Down Nodes (NodesToShutdown)"; private static final String OVERALL_REQUEST_METRIC = "[MEM] Request Rate: All"; private static final String OVERALL_AVG_BYTES_WRITE_METRIC = "[MEM] Average Bytes written to OS per write"; private static final String OVERALL_AVG_BYTES_READ_METRIC = "[MEM] Average Bytes read from OS per read"; private static final String OVERALL_AVG_TIME_ON_WIRE_METRIC = "[MEM] Average Time on wire for operations (Âµs)"; private static final String OVERALL_RESPONSE_METRIC = "[MEM] Response Rate: All (Failure + Success + Retry)"; private static final String OVERALL_RESPONSE_RETRY_METRIC = "[MEM] Response Rate: Retry"; private static final String OVERALL_RESPONSE_FAIL_METRIC = "[MEM] Response Rate: Failure"; private static final String OVERALL_RESPONSE_SUCC_METRIC = "[MEM] Response Rate: Success"; protected volatile boolean shutDown = false; private final boolean shouldOptimize; protected Selector selector = null; protected final NodeLocator locator; protected final FailureMode failureMode; private final long maxDelay; private int emptySelects = 0; private final int bufSize; private final ConnectionFactory connectionFactory; protected final ConcurrentLinkedQueue<MemcachedNode> addedQueue; private final SortedMap<Long, MemcachedNode> reconnectQueue; protected volatile boolean running = true; private final Collection<ConnectionObserver> connObservers = new ConcurrentLinkedQueue<ConnectionObserver>(); private final OperationFactory opFact; private final int timeoutExceptionThreshold; private final List<Operation> retryOps; protected final ConcurrentLinkedQueue<MemcachedNode> nodesToShutdown; private final boolean verifyAliveOnConnect; private final ExecutorService listenerExecutorService; protected final MetricCollector metrics; protected final MetricType metricType; private final int wakeupDelay; private final int retryQueueSize; public MemcachedConnection(final int bufSize, final ConnectionFactory f, final List<InetSocketAddress> a, final Collection<ConnectionObserver> obs, final FailureMode fm, final OperationFactory opfactory) throws IOException { connObservers.addAll(obs); reconnectQueue = new TreeMap<Long, MemcachedNode>(); addedQueue = new ConcurrentLinkedQueue<MemcachedNode>(); failureMode = fm; shouldOptimize = f.shouldOptimize(); maxDelay = TimeUnit.SECONDS.toMillis(f.getMaxReconnectDelay()); opFact = opfactory; timeoutExceptionThreshold = f.getTimeoutExceptionThreshold(); selector = Selector.open(); retryOps = Collections.synchronizedList(new ArrayList<Operation>()); nodesToShutdown = new ConcurrentLinkedQueue<MemcachedNode>(); listenerExecutorService = f.getListenerExecutorService(); this.bufSize = bufSize; this.connectionFactory = f; String verifyAlive = System.getProperty("net.spy.verifyAliveOnConnect"); if(verifyAlive != null && verifyAlive.equals("true")) { verifyAliveOnConnect = true; } else { verifyAliveOnConnect = false; } wakeupDelay = Integer.parseInt( System.getProperty("net.spy.wakeupDelay", Integer.toString(DEFAULT_WAKEUP_DELAY))); retryQueueSize = Integer.parseInt(System.getProperty("net.spy.retryQueueSize", Integer.toString(DEFAULT_RETRY_QUEUE_SIZE))); getLogger().info("Setting retryQueueSize to " + retryQueueSize); List<MemcachedNode> connections = createConnections(a); locator = f.createLocator(connections); metrics = f.getMetricCollector(); metricType = f.enableMetrics(); registerMetrics(); setName("Memcached IO over " + this); setDaemon(f.isDaemon()); start(); } protected void registerMetrics() { if (metricType.equals(MetricType.DEBUG) || metricType.equals(MetricType.PERFORMANCE)) { metrics.addHistogram(OVERALL_AVG_BYTES_READ_METRIC); metrics.addHistogram(OVERALL_AVG_BYTES_WRITE_METRIC); metrics.addHistogram(OVERALL_AVG_TIME_ON_WIRE_METRIC); metrics.addMeter(OVERALL_RESPONSE_METRIC); metrics.addMeter(OVERALL_REQUEST_METRIC); if (metricType.equals(MetricType.DEBUG)) { metrics.addCounter(RECON_QUEUE_METRIC); metrics.addCounter(SHUTD_QUEUE_METRIC); metrics.addMeter(OVERALL_RESPONSE_RETRY_METRIC); metrics.addMeter(OVERALL_RESPONSE_SUCC_METRIC); metrics.addMeter(OVERALL_RESPONSE_FAIL_METRIC); } } } protected List<MemcachedNode> createConnections( final Collection<InetSocketAddress> addrs) throws IOException { List<MemcachedNode> connections = new ArrayList<MemcachedNode>(addrs.size()); for (SocketAddress sa : addrs) { SocketChannel ch = SocketChannel.open(); ch.configureBlocking(false); MemcachedNode qa = connectionFactory.createMemcachedNode(sa, ch, bufSize); qa.setConnection(this); int ops = 0; Socket socket = ch.socket(); socket.setTcpNoDelay(!connectionFactory.useNagleAlgorithm()); socket.setKeepAlive(connectionFactory.getKeepAlive()); try { if (ch.connect(sa)) { getLogger().info("Connected to %s immediately", qa); connected(qa); } else { getLogger().info("Added %s to connect queue", qa); ops = SelectionKey.OP_CONNECT; } selector.wakeup(); qa.setSk(ch.register(selector, ops, qa)); assert ch.isConnected() || qa.getSk().interestOps() == SelectionKey.OP_CONNECT : "Not connected, and not wanting to connect"; } catch (SocketException e) { getLogger().warn("Socket error on initial connect", e); queueReconnect(qa); } connections.add(qa); } return connections; } private boolean selectorsMakeSense() { for (MemcachedNode qa : locator.getAll()) { if (qa.getSk() != null && qa.getSk().isValid()) { if (qa.getChannel().isConnected()) { int sops = qa.getSk().interestOps(); int expected = 0; if (qa.hasReadOp()) { expected |= SelectionKey.OP_READ; } if (qa.hasWriteOp()) { expected |= SelectionKey.OP_WRITE; } if (qa.getBytesRemainingToWrite() > 0) { expected |= SelectionKey.OP_WRITE; } assert sops == expected : "Invalid ops: " + qa + ", expected " + expected + ", got " + sops; } else { int sops = qa.getSk().interestOps(); assert sops == SelectionKey.OP_CONNECT : "Not connected, and not watching for connect: " + sops; } } } getLogger().debug("Checked the selectors."); return true; } public void handleIO() throws IOException { if (shutDown) { getLogger().debug("No IO while shut down."); return; } handleInputQueue(); getLogger().debug("Done dealing with queue."); long delay = wakeupDelay; if (!reconnectQueue.isEmpty()) { long now = System.currentTimeMillis(); long then = reconnectQueue.firstKey(); delay = Math.max(then - now, 1); } getLogger().debug("Selecting with delay of %sms", delay); assert selectorsMakeSense() : "Selectors don't make sense."; int selected = selector.select(delay); if (shutDown) { return; } else if (selected == 0 && addedQueue.isEmpty()) { handleWokenUpSelector(); } else if (selector.selectedKeys().isEmpty()) { handleEmptySelects(); } else { getLogger().debug("Selected %d, selected %d keys", selected, selector.selectedKeys().size()); emptySelects = 0; Iterator<SelectionKey> iterator = selector.selectedKeys().iterator(); while(iterator.hasNext()) { SelectionKey sk = iterator.next(); handleIO(sk); iterator.remove(); } } handleOperationalTasks(); } protected void handleWokenUpSelector() { } private void handleOperationalTasks() throws IOException { checkPotentiallyTimedOutConnection(); if (!shutDown && !reconnectQueue.isEmpty()) { attemptReconnects(); } if (!retryOps.isEmpty()) { ArrayList<Operation> operations = new ArrayList<Operation>(retryOps); retryOps.clear(); redistributeOperations(operations); } handleShutdownQueue(); } private void handleEmptySelects() { getLogger().debug("No selectors ready, interrupted: %b", Thread.interrupted()); if (++emptySelects > DOUBLE_CHECK_EMPTY) { for (SelectionKey sk : selector.keys()) { getLogger().debug("%s has %s, interested in %s", sk, sk.readyOps(), sk.interestOps()); if (sk.readyOps() != 0) { getLogger().debug("%s has a ready op, handling IO", sk); handleIO(sk); } else { lostConnection((MemcachedNode) sk.attachment()); } } assert emptySelects < EXCESSIVE_EMPTY : "Too many empty selects"; } } private void handleShutdownQueue() throws IOException { for (MemcachedNode qa : nodesToShutdown) { if (!addedQueue.contains(qa)) { nodesToShutdown.remove(qa); metrics.decrementCounter(SHUTD_QUEUE_METRIC); Collection<Operation> notCompletedOperations = qa.destroyInputQueue(); if (qa.getChannel() != null) { qa.getChannel().close(); qa.setSk(null); if (qa.getBytesRemainingToWrite() > 0) { getLogger().warn("Shut down with %d bytes remaining to write", qa.getBytesRemainingToWrite()); } getLogger().debug("Shut down channel %s", qa.getChannel()); } redistributeOperations(notCompletedOperations); } } } private void checkPotentiallyTimedOutConnection() { boolean stillCheckingTimeouts = true; while (stillCheckingTimeouts) { try { for (SelectionKey sk : selector.keys()) { MemcachedNode mn = (MemcachedNode) sk.attachment(); if (mn.getContinuousTimeout() > timeoutExceptionThreshold) { getLogger().warn("%s exceeded continuous timeout threshold", sk); lostConnection(mn); } } stillCheckingTimeouts = false; } catch(ConcurrentModificationException e) { getLogger().warn("Retrying selector keys after " + "ConcurrentModificationException caught", e); continue; } } } private void handleInputQueue() { if (!addedQueue.isEmpty()) { getLogger().debug("Handling queue"); Collection<MemcachedNode> toAdd = new HashSet<MemcachedNode>(); Collection<MemcachedNode> todo = new HashSet<MemcachedNode>(); MemcachedNode qaNode; while ((qaNode = addedQueue.poll()) != null) { todo.add(qaNode); } for (MemcachedNode node : todo) { boolean readyForIO = false; if (node.isActive()) { if (node.getCurrentWriteOp() != null) { readyForIO = true; getLogger().debug("Handling queued write %s", node); } } else { toAdd.add(node); } node.copyInputQueue(); if (readyForIO) { try { if (node.getWbuf().hasRemaining()) { handleWrites(node); } } catch (IOException e) { getLogger().warn("Exception handling write", e); lostConnection(node); } } node.fixupOps(); } addedQueue.addAll(toAdd); } } public boolean addObserver(final ConnectionObserver obs) { return connObservers.add(obs); } public boolean removeObserver(final ConnectionObserver obs) { return connObservers.remove(obs); } private void connected(final MemcachedNode node) { assert node.getChannel().isConnected() : "Not connected."; int rt = node.getReconnectCount(); node.connected(); for (ConnectionObserver observer : connObservers) { observer.connectionEstablished(node.getSocketAddress(), rt); } } private void lostConnection(final MemcachedNode node) { queueReconnect(node); for (ConnectionObserver observer : connObservers) { observer.connectionLost(node.getSocketAddress()); } } boolean belongsToCluster(final MemcachedNode node) { for (MemcachedNode n : locator.getAll()) { if (n.getSocketAddress().equals(node.getSocketAddress())) { return true; } } return false; } private void handleIO(final SelectionKey sk) { MemcachedNode node = (MemcachedNode) sk.attachment(); try { getLogger().debug("Handling IO for: %s (r=%s, w=%s, c=%s, op=%s)", sk, sk.isReadable(), sk.isWritable(), sk.isConnectable(), sk.attachment()); if (sk.isConnectable() && belongsToCluster(node)) { getLogger().debug("Connection state changed for %s", sk); final SocketChannel channel = node.getChannel(); if (channel.finishConnect()) { finishConnect(sk, node); } else { assert !channel.isConnected() : "connected"; } } else { handleReadsAndWrites(sk, node); } } catch (ClosedChannelException e) { if (!shutDown) { getLogger().info("Closed channel and not shutting down. Queueing" + " reconnect on %s", node, e); lostConnection(node); } } catch (ConnectException e) { getLogger().info("Reconnecting due to failure to connect to %s", node, e); queueReconnect(node); } catch (OperationException e) { node.setupForAuth(); getLogger().info("Reconnection due to exception handling a memcached " + "operation on %s. This may be due to an authentication failure.", node, e); lostConnection(node); } catch (Exception e) { node.setupForAuth(); getLogger().info("Reconnecting due to exception on %s", node, e); lostConnection(node); } node.fixupOps(); } private void handleReadsAndWrites(final SelectionKey sk, final MemcachedNode node) throws IOException { if (sk.isValid() && sk.isReadable()) { handleReads(node); } if (sk.isValid() && sk.isWritable()) { handleWrites(node); } } private void finishConnect(final SelectionKey sk, final MemcachedNode node) throws IOException { if (verifyAliveOnConnect) { final CountDownLatch latch = new CountDownLatch(1); final OperationFuture<Boolean> rv = new OperationFuture<Boolean>("noop", latch, 2500, listenerExecutorService); NoopOperation testOp = opFact.noop(new OperationCallback() { public void receivedStatus(OperationStatus status) { rv.set(status.isSuccess(), status); } @Override public void complete() { latch.countDown(); } }); testOp.setHandlingNode(node); testOp.initialize(); checkState(); insertOperation(node, testOp); node.copyInputQueue(); boolean done = false; if (sk.isValid()) { long timeout = TimeUnit.MILLISECONDS.toNanos( connectionFactory.getOperationTimeout()); long stop = System.nanoTime() + timeout; while (stop > System.nanoTime()) { handleWrites(node); handleReads(node); if(done = (latch.getCount() == 0)) { break; } } } if (!done || testOp.isCancelled() || testOp.hasErrored() || testOp.isTimedOut()) { throw new ConnectException("Could not send noop upon connect! " + "This may indicate a running, but not responding memcached " + "instance."); } } connected(node); addedQueue.offer(node); if (node.getWbuf().hasRemaining()) { handleWrites(node); } } private void handleWrites(final MemcachedNode node) throws IOException { node.fillWriteBuffer(shouldOptimize); boolean canWriteMore = node.getBytesRemainingToWrite() > 0; while (canWriteMore) { int wrote = node.writeSome(); metrics.updateHistogram(OVERALL_AVG_BYTES_WRITE_METRIC, wrote); node.fillWriteBuffer(shouldOptimize); canWriteMore = wrote > 0 && node.getBytesRemainingToWrite() > 0; } } private void handleReads(final MemcachedNode node) throws IOException { Operation currentOp = node.getCurrentReadOp(); if (currentOp instanceof TapAckOperationImpl) { node.removeCurrentReadOp(); return; } ByteBuffer rbuf = node.getRbuf(); final SocketChannel channel = node.getChannel(); int read = channel.read(rbuf); metrics.updateHistogram(OVERALL_AVG_BYTES_READ_METRIC, read); if (read < 0) { currentOp = handleReadsWhenChannelEndOfStream(currentOp, node, rbuf); } while (read > 0) { getLogger().debug("Read %d bytes", read); rbuf.flip(); while (rbuf.remaining() > 0) { if (currentOp == null) { throw new IllegalStateException("No read operation."); } long timeOnWire = System.nanoTime() - currentOp.getWriteCompleteTimestamp(); metrics.updateHistogram(OVERALL_AVG_TIME_ON_WIRE_METRIC, (int)(timeOnWire / 1000)); metrics.markMeter(OVERALL_RESPONSE_METRIC); synchronized(currentOp) { readBufferAndLogMetrics(currentOp, rbuf, node); } currentOp = node.getCurrentReadOp(); } rbuf.clear(); read = channel.read(rbuf); node.completedRead(); } } private void readBufferAndLogMetrics(final Operation currentOp, final ByteBuffer rbuf, final MemcachedNode node) throws IOException { currentOp.readFromBuffer(rbuf); if (currentOp.getState() == OperationState.COMPLETE) { getLogger().debug("Completed read op: %s and giving the next %d " + "bytes", currentOp, rbuf.remaining()); Operation op = node.removeCurrentReadOp(); assert op == currentOp : "Expected to pop " + currentOp + " got " + op; if (op.hasErrored()) { metrics.markMeter(OVERALL_RESPONSE_FAIL_METRIC); } else { metrics.markMeter(OVERALL_RESPONSE_SUCC_METRIC); } } else if (currentOp.getState() == OperationState.RETRY) { handleRetryInformation(currentOp.getErrorMsg()); getLogger().debug("Reschedule read op due to NOT_MY_VBUCKET error: " + "%s ", currentOp); ((VBucketAware) currentOp).addNotMyVbucketNode( currentOp.getHandlingNode()); Operation op = node.removeCurrentReadOp(); assert op == currentOp : "Expected to pop " + currentOp + " got " + op; retryOperation(currentOp); metrics.markMeter(OVERALL_RESPONSE_RETRY_METRIC); } } private Operation handleReadsWhenChannelEndOfStream(final Operation currentOp, final MemcachedNode node, final ByteBuffer rbuf) throws IOException { if (currentOp instanceof TapOperation) { currentOp.getCallback().complete(); ((TapOperation) currentOp).streamClosed(OperationState.COMPLETE); getLogger().debug("Completed read op: %s and giving the next %d bytes", currentOp, rbuf.remaining()); Operation op = node.removeCurrentReadOp(); assert op == currentOp : "Expected to pop " + currentOp + " got " + op; return node.getCurrentReadOp(); } else { throw new IOException("Disconnected unexpected, will reconnect."); } } static String dbgBuffer(ByteBuffer b, int size) { StringBuilder sb = new StringBuilder(); byte[] bytes = b.array(); for (int i = 0; i < size; i++) { char ch = (char) bytes[i]; if (Character.isWhitespace(ch) || Character.isLetterOrDigit(ch)) { sb.append(ch); } else { sb.append("\\x"); sb.append(Integer.toHexString(bytes[i] & 0xff)); } } return sb.toString(); } protected void handleRetryInformation(final byte[] retryMessage) { getLogger().debug("Got RETRY message: " + new String(retryMessage) + ", but not handled."); } protected void queueReconnect(final MemcachedNode node) { if (shutDown) { return; } getLogger().warn("Closing, and reopening %s, attempt %d.", node, node.getReconnectCount()); if (node.getSk() != null) { node.getSk().cancel(); assert !node.getSk().isValid() : "Cancelled selection key is valid"; } node.reconnecting(); try { if (node.getChannel() != null && node.getChannel().socket() != null) { node.getChannel().socket().close(); } else { getLogger().info("The channel or socket was null for %s", node); } } catch (IOException e) { getLogger().warn("IOException trying to close a socket", e); } node.setChannel(null); long delay = (long) Math.min(maxDelay, Math.pow(2, node.getReconnectCount()) * 1000); long reconnectTime = System.currentTimeMillis() + delay; while (reconnectQueue.containsKey(reconnectTime)) { reconnectTime++; } reconnectQueue.put(reconnectTime, node); metrics.incrementCounter(RECON_QUEUE_METRIC); node.setupResend(); if (failureMode == FailureMode.Redistribute) { redistributeOperations(node.destroyInputQueue()); } else if (failureMode == FailureMode.Cancel) { cancelOperations(node.destroyInputQueue()); } } private void cancelOperations(final Collection<Operation> ops) { for (Operation op : ops) { op.cancel(); } } public void redistributeOperations(final Collection<Operation> ops) { for (Operation op : ops) { redistributeOperation(op); } } public void redistributeOperation(Operation op) { if (op.isCancelled() || op.isTimedOut()) { return; } if (op.getCloneCount() >= MAX_CLONE_COUNT) { getLogger().warn("Cancelling operation " + op + "because it has been " + "retried (cloned) more than " + MAX_CLONE_COUNT + "times."); op.cancel(); return; } if (op.getState() == OperationState.WRITE_QUEUED && op.getHandlingNode() != null) { addOperation(op.getHandlingNode(), op); return; } if (op instanceof MultiGetOperationImpl) { for (String key : ((MultiGetOperationImpl) op).getRetryKeys()) { addOperation(key, opFact.get(key, (GetOperation.Callback) op.getCallback())); } } else if (op instanceof KeyedOperation) { KeyedOperation ko = (KeyedOperation) op; int added = 0; for (Operation newop : opFact.clone(ko)) { if (newop instanceof KeyedOperation) { KeyedOperation newKeyedOp = (KeyedOperation) newop; for (String k : newKeyedOp.getKeys()) { addOperation(k, newop); op.addClone(newop); newop.setCloneCount(op.getCloneCount()+1); } } else { newop.cancel(); getLogger().warn("Could not redistribute cloned non-keyed " + "operation", newop); } added++; } assert added > 0 : "Didn't add any new operations when redistributing"; } else { op.cancel(); } } private void attemptReconnects() { final long now = System.currentTimeMillis(); final Map<MemcachedNode, Boolean> seen = new IdentityHashMap<MemcachedNode, Boolean>(); final List<MemcachedNode> rereQueue = new ArrayList<MemcachedNode>(); SocketChannel ch = null; Iterator<MemcachedNode> i = reconnectQueue.headMap(now).values().iterator(); while(i.hasNext()) { final MemcachedNode node = i.next(); i.remove(); metrics.decrementCounter(RECON_QUEUE_METRIC); try { if (!belongsToCluster(node)) { getLogger().debug("Node does not belong to cluster anymore, " + "skipping reconnect: %s", node); continue; } if (!seen.containsKey(node)) { seen.put(node, Boolean.TRUE); getLogger().info("Reconnecting %s", node); ch = SocketChannel.open(); ch.configureBlocking(false); ch.socket().setTcpNoDelay(!connectionFactory.useNagleAlgorithm()); int ops = 0; if (ch.connect(node.getSocketAddress())) { connected(node); addedQueue.offer(node); getLogger().info("Immediately reconnected to %s", node); assert ch.isConnected(); } else { ops = SelectionKey.OP_CONNECT; } node.registerChannel(ch, ch.register(selector, ops, node)); assert node.getChannel() == ch : "Channel was lost."; } else { getLogger().debug("Skipping duplicate reconnect request for %s", node); } } catch (SocketException e) { getLogger().warn("Error on reconnect", e); rereQueue.add(node); } catch (Exception e) { getLogger().error("Exception on reconnect, lost node %s", node, e); } finally { potentiallyCloseLeakingChannel(ch, node); } } for (MemcachedNode n : rereQueue) { queueReconnect(n); } } private void potentiallyCloseLeakingChannel(final SocketChannel ch, final MemcachedNode node) { if (ch != null && !ch.isConnected() && !ch.isConnectionPending()) { try { ch.close(); } catch (IOException e) { getLogger().error("Exception closing channel: %s", node, e); } } } public NodeLocator getLocator() { return locator; } public void enqueueOperation(final String key, final Operation o) { checkState(); StringUtils.validateKey(key, opFact instanceof BinaryOperationFactory); addOperation(key, o); } protected void addOperation(final String key, final Operation o) { MemcachedNode placeIn = null; MemcachedNode primary = locator.getPrimary(key); if (primary.isActive() || failureMode == FailureMode.Retry) { placeIn = primary; } else if (failureMode == FailureMode.Cancel) { o.cancel(); } else { Iterator<MemcachedNode> i = locator.getSequence(key); while (placeIn == null && i.hasNext()) { MemcachedNode n = i.next(); if (n.isActive()) { placeIn = n; } } if (placeIn == null) { placeIn = primary; this.getLogger().warn("Could not redistribute to another node, " + "retrying primary node for %s.", key); } } assert o.isCancelled() || placeIn != null : "No node found for key " + key; if (placeIn != null) { addOperation(placeIn, o); } else { assert o.isCancelled() : "No node found for " + key + " (and not " + "immediately cancelled)"; } } public void insertOperation(final MemcachedNode node, final Operation o) { o.setHandlingNode(node); o.initialize(); node.insertOp(o); addedQueue.offer(node); metrics.markMeter(OVERALL_REQUEST_METRIC); Selector s = selector.wakeup(); assert s == selector : "Wakeup returned the wrong selector."; getLogger().debug("Added %s to %s", o, node); } protected void addOperation(final MemcachedNode node, final Operation o) { if (!node.isAuthenticated()) { retryOperation(o); return; } o.setHandlingNode(node); o.initialize(); node.addOp(o); addedQueue.offer(node); metrics.markMeter(OVERALL_REQUEST_METRIC); Selector s = selector.wakeup(); assert s == selector : "Wakeup returned the wrong selector."; getLogger().debug("Added %s to %s", o, node); } public void addOperations(final Map<MemcachedNode, Operation> ops) { for (Map.Entry<MemcachedNode, Operation> me : ops.entrySet()) { addOperation(me.getKey(), me.getValue()); } } public CountDownLatch broadcastOperation(final BroadcastOpFactory of) { return broadcastOperation(of, locator.getAll()); } public CountDownLatch broadcastOperation(final BroadcastOpFactory of, final Collection<MemcachedNode> nodes) { final CountDownLatch latch = new CountDownLatch(nodes.size()); for (MemcachedNode node : nodes) { getLogger().debug("broadcast Operation: node = " + node); Operation op = of.newOp(node, latch); op.initialize(); node.addOp(op); op.setHandlingNode(node); addedQueue.offer(node); metrics.markMeter(OVERALL_REQUEST_METRIC); } Selector s = selector.wakeup(); assert s == selector : "Wakeup returned the wrong selector."; return latch; } public void shutdown() throws IOException { shutDown = true; try { Selector s = selector.wakeup(); assert s == selector : "Wakeup returned the wrong selector."; for (MemcachedNode node : locator.getAll()) { if (node.getChannel() != null) { node.getChannel().close(); node.setSk(null); if (node.getBytesRemainingToWrite() > 0) { getLogger().warn("Shut down with %d bytes remaining to write", node.getBytesRemainingToWrite()); } getLogger().debug("Shut down channel %s", node.getChannel()); } } selector.close(); getLogger().debug("Shut down selector %s", selector); } finally { running = false; } } @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append("{MemcachedConnection to"); for (MemcachedNode qa : locator.getAll()) { sb.append(" ").append(qa.getSocketAddress()); } sb.append("}"); return sb.toString(); } public String connectionsStatus() { StringBuilder connStatus = new StringBuilder(); connStatus.append("Connection Status {"); for (MemcachedNode node : locator.getAll()) { connStatus .append(" ") .append(node.getSocketAddress()) .append(" active: ") .append(node.isActive()) .append(", authed: ") .append(node.isAuthenticated()) .append(MessageFormat.format(", last read: {0} ms ago", node.lastReadDelta())); } connStatus.append(" }"); return connStatus.toString(); } public static void opTimedOut(final Operation op) { MemcachedConnection.setTimeout(op, true); } public static void opSucceeded(final Operation op) { MemcachedConnection.setTimeout(op, false); } private static void setTimeout(final Operation op, final boolean isTimeout) { Logger logger = LoggerFactory.getLogger(MemcachedConnection.class); try { if (op == null || op.isTimedOutUnsent()) { return; } MemcachedNode node = op.getHandlingNode(); if (node != null) { node.setContinuousTimeout(isTimeout); } } catch (Exception e) { logger.error(e.getMessage()); } } protected void checkState() { if (shutDown) { throw new IllegalStateException("Shutting down"); } assert isAlive() : "IO Thread is not running."; } @Override public void run() { while (running) { try { handleIO(); } catch (IOException e) { logRunException(e); } catch (CancelledKeyException e) { logRunException(e); } catch (ClosedSelectorException e) { logRunException(e); } catch (IllegalStateException e) { logRunException(e); } catch (ConcurrentModificationException e) { logRunException(e); } } getLogger().info("Shut down memcached client"); } private void logRunException(final Exception e) { if (shutDown) { getLogger().debug("Exception occurred during shutdown", e); } else { getLogger().warn("Problem handling memcached IO", e); } } public boolean isShutDown() { return shutDown; } public void retryOperation(Operation op) { if (retryQueueSize >= 0 && retryOps.size() >= retryQueueSize) { if (!op.isCancelled()) { op.cancel(); } } retryOps.add(op); } }
public class HadoopSpillableTupleList extends SpillableTupleList { private static final Logger LOG = LoggerFactory . getLogger ( HadoopSpillableTupleList . class ) ; public static final String defaultCodecs = "org . apache . hadoop . io . compress . GzipCodec , org . apache . hadoop . io . compress . DefaultCodec" ; private final CompressionCodec codec ; private final TupleSerialization tupleSerialization ; public static synchronized CompressionCodec getCodec ( FlowProcess < ? extends Configuration > flowProcess , String defaultCodecs ) { Class < ? extends CompressionCodec > codecClass = getCodecClass ( flowProcess , defaultCodecs , CompressionCodec . class ) ; if ( codecClass == null ) return null ; if ( flowProcess instanceof FlowProcessWrapper ) flowProcess = ( ( FlowProcessWrapper ) flowProcess ) . getDelegate ( ) ; return ReflectionUtils . newInstance ( codecClass , flowProcess . getConfig ( ) ) ; } public HadoopSpillableTupleList ( int threshold , CompressionCodec codec , Configuration configuration ) { super ( threshold ) ; this . codec = codec ; if ( configuration == null ) this . tupleSerialization = new TupleSerialization ( ) ; else this . tupleSerialization = new TupleSerialization ( configuration ) ; } public HadoopSpillableTupleList ( int threshold , TupleSerialization tupleSerialization , CompressionCodec codec ) { super ( threshold ) ; this . tupleSerialization = tupleSerialization ; this . codec = codec ; } @ Override protected TupleOutputStream createTupleOutputStream ( File file ) { OutputStream outputStream ; try { outputStream = new FileOutputStream ( file ) ; Compressor compressor = null ; if ( codec != null ) { compressor = getCompressor ( ) ; outputStream = codec . createOutputStream ( outputStream , compressor ) ; } final Compressor finalCompressor = compressor ; return new HadoopTupleOutputStream ( outputStream , tupleSerialization . getElementWriter ( ) ) { @ Override public void close ( ) throws IOException { try { super . close ( ) ; } finally { if ( finalCompressor != null ) CodecPool . returnCompressor ( finalCompressor ) ; } } } ; } catch ( IOException exception ) { throw new TupleException ( "unable to create temporary file input stream" , exception ) ; } } private Compressor getCompressor ( ) { try { return CodecPool . getCompressor ( codec ) ; } catch ( OutOfMemoryError error ) { System . gc ( ) ; LOG . info ( "received OOME when allocating compressor for codec : { } , retrying once" , codec . getClass ( ) . getCanonicalName ( ) , error ) ; return CodecPool . getCompressor ( codec ) ; } } @ Override protected TupleInputStream createTupleInputStream ( File file ) { try { InputStream inputStream ; inputStream = new FileInputStream ( file ) ; Decompressor decompressor = null ; if ( codec != null ) { decompressor = getDecompressor ( ) ; inputStream = codec . createInputStream ( inputStream , decompressor ) ; } final Decompressor finalDecompressor = decompressor ; return new HadoopTupleInputStream ( inputStream , tupleSerialization . getElementReader ( ) ) { @ Override public void close ( ) throws IOException { try { super . close ( ) ; } finally { if ( finalDecompressor != null ) CodecPool . returnDecompressor ( finalDecompressor ) ; } } } ; } catch ( IOException exception ) { throw new TupleException ( "unable to create temporary file output stream" , exception ) ; } } private Decompressor getDecompressor ( ) { try { return CodecPool . getDecompressor ( codec ) ; } catch ( OutOfMemoryError error ) { System . gc ( ) ; LOG . info ( "received OOME when allocating decompressor for codec : { } , retrying once" , codec . getClass ( ) . getCanonicalName ( ) , error ) ; return CodecPool . getDecompressor ( codec ) ; } } }
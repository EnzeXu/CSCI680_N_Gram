public class TapOutputCollector implements OutputCollector , Closeable { private static final Logger LOG = LoggerFactory . getLogger ( TapOutputCollector . class ) ; public static final String PART_TASK_PATTERN = "%s%spart-%05d" ; public static final String PART_TASK_SEQ_PATTERN = "%s%spart-%05d-%05d" ; private Configuration conf ; private RecordWriter writer ; private String filenamePattern ; private String filename ; private Tap < Configuration , RecordReader , OutputCollector > tap ; private String prefix ; private long sequence ; private boolean isFileOutputFormat ; private final FlowProcess < ? extends Configuration > flowProcess ; public TapOutputCollector ( FlowProcess < ? extends Configuration > flowProcess , Tap < Configuration , RecordReader , OutputCollector > tap ) throws IOException { this ( flowProcess , tap , null ) ; } public TapOutputCollector ( FlowProcess < ? extends Configuration > flowProcess , Tap < Configuration , RecordReader , OutputCollector > tap , String prefix ) throws IOException { this ( flowProcess , tap , prefix , -1 ) ; } public TapOutputCollector ( FlowProcess < ? extends Configuration > flowProcess , Tap < Configuration , RecordReader , OutputCollector > tap , String prefix , long sequence ) throws IOException { this . tap = tap ; this . sequence = sequence ; this . prefix = prefix == null || prefix . length ( ) == 0 ? null : prefix ; this . flowProcess = flowProcess ; this . conf = this . flowProcess . getConfigCopy ( ) ; this . filenamePattern = this . conf . get ( "cascading . tapcollector . partname" , sequence == -1 ? PART_TASK_PATTERN : PART_TASK_SEQ_PATTERN ) ; initialize ( ) ; } protected void initialize ( ) throws IOException { tap . sinkConfInit ( flowProcess , conf ) ; OutputFormat outputFormat = asJobConfInstance ( conf ) . getOutputFormat ( ) ; isFileOutputFormat = outputFormat instanceof FileOutputFormat ; if ( isFileOutputFormat ) { Hadoop18TapUtil . setupJob ( conf ) ; Hadoop18TapUtil . setupTask ( conf ) ; int partition = conf . getInt ( "mapred . task . partition" , conf . getInt ( "mapreduce . task . partition" , 0 ) ) ; long localSequence = sequence == -1 ? 0 : sequence ; if ( prefix != null ) filename = String . format ( filenamePattern , prefix , "/" , partition , localSequence ) ; else filename = String . format ( filenamePattern , "" , "" , partition , localSequence ) ; } LOG . info ( "creating path : { } " , filename ) ; writer = outputFormat . getRecordWriter ( null , asJobConfInstance ( conf ) , filename , getReporter ( ) ) ; } private Reporter getReporter ( ) { Reporter reporter = Reporter . NULL ; if ( flowProcess instanceof MapRed ) reporter = ( ( MapRed ) flowProcess ) . getReporter ( ) ; return reporter ; } public void collect ( Object writableComparable , Object writable ) throws IOException { flowProcess . keepAlive ( ) ; writer . write ( writableComparable , writable ) ; } public void close ( ) { try { if ( isFileOutputFormat ) LOG . info ( "closing tap collector for : { } " , new Path ( tap . getIdentifier ( ) , filename ) ) ; else LOG . info ( "closing tap collector for : { } " , tap ) ; try { writer . close ( getReporter ( ) ) ; } finally { if ( isFileOutputFormat ) { boolean needsTaskCommit = Hadoop18TapUtil . needsTaskCommit ( conf ) ; boolean cleanJob = true ; if ( needsTaskCommit ) cleanJob = Hadoop18TapUtil . commitTask ( conf ) ; if ( cleanJob ) Hadoop18TapUtil . cleanupJob ( conf ) ; if ( !HadoopUtil . isInflow ( conf ) ) Hadoop18TapUtil . writeSuccessMarker ( conf ) ; } } } catch ( IOException exception ) { LOG . warn ( "exception closing : { } " , filename , exception ) ; throw new TapException ( "exception closing : " + filename , exception ) ; } } }
public class HadoopPlanner extends FlowPlanner<HadoopFlow, JobConf> { private static final Logger LOG = LoggerFactory.getLogger( HadoopPlanner.class ); public static final String PLATFORM_NAME = "hadoop"; private JobConf defaultJobConf; private Class intermediateSchemeClass; public static void copyJobConf( Map<Object, Object> properties, JobConf jobConf ) { for( Map.Entry<String, String> entry : jobConf ) properties.put( entry.getKey(), entry.getValue() ); } public static JobConf createJobConf( Map<Object, Object> properties ) { JobConf conf = new JobConf(); copyProperties( conf, properties ); return conf; } public static void copyProperties( JobConf jobConf, Map<Object, Object> properties ) { if( properties instanceof Properties ) { Properties props = (Properties) properties; Set<String> keys = props.stringPropertyNames(); for( String key : keys ) jobConf.set( key, props.getProperty( key ) ); } else { for( Map.Entry<Object, Object> entry : properties.entrySet() ) { if( entry.getValue() != null ) jobConf.set( entry.getKey().toString(), entry.getValue().toString() ); } } } @Override public PlannerInfo getPlannerInfo( String registryName ) { return new PlannerInfo( getClass().getSimpleName(), PLATFORM_NAME, registryName ); } @Override public JobConf getDefaultConfig() { return defaultJobConf; } @Override public PlatformInfo getPlatformInfo() { return HadoopUtil.getPlatformInfo( JobConf.class, "org/apache/hadoop", "Hadoop MR" ); } @Override public void initialize( FlowConnector flowConnector, Map<Object, Object> properties ) { super.initialize( flowConnector, properties ); defaultJobConf = HadoopUtil.createJobConf( properties, createJobConf( properties ) ); checkPlatform( defaultJobConf ); intermediateSchemeClass = flowConnector.getIntermediateSchemeClass( properties ); Class type = AppProps.getApplicationJarClass( properties ); if( defaultJobConf.getJar() == null && type != null ) defaultJobConf.setJarByClass( type ); String path = AppProps.getApplicationJarPath( properties ); if( defaultJobConf.getJar() == null && path != null ) defaultJobConf.setJar( path ); if( defaultJobConf.getJar() == null ) defaultJobConf.setJarByClass( HadoopUtil.findMainClass( HadoopPlanner.class ) ); AppProps.setApplicationJarPath( properties, defaultJobConf.getJar() ); LOG.info( "using application jar: {}", defaultJobConf.getJar() ); } @Override public void configRuleRegistryDefaults( RuleRegistry ruleRegistry ) { super.configRuleRegistryDefaults( ruleRegistry ); ruleRegistry.addDefaultElementFactory( IntermediateTapElementFactory.TEMP_TAP, new TempTapElementFactory() ); if( PropertyUtil.getBooleanProperty( getDefaultProperties(), FlowConnectorProps.ENABLE_DECORATE_ACCUMULATED_TAP, true ) ) ruleRegistry.addDefaultElementFactory( IntermediateTapElementFactory.ACCUMULATED_TAP, new TempTapElementFactory( DistCacheTap.class.getName() ) ); } protected void checkPlatform( Configuration conf ) { if( HadoopUtil.isYARN( conf ) ) LOG.warn( "running YARN based flows on Hadoop 1.x may cause problems, please use the 'cascading-hadoop3-mr1' dependencies" ); } @Override protected HadoopFlow createFlow( FlowDef flowDef ) { return new HadoopFlow( getPlatformInfo(), getDefaultProperties(), getDefaultConfig(), flowDef ); } @Override public FlowStepFactory<JobConf> getFlowStepFactory() { return new BaseFlowStepFactory<JobConf>( getFlowNodeFactory() ) { @Override public FlowStep<JobConf> createFlowStep( ElementGraph stepElementGraph, FlowNodeGraph flowNodeGraph ) { return new HadoopFlowStep( stepElementGraph, flowNodeGraph ); } }; } public URI getDefaultURIScheme( Tap tap ) { return ( (Hfs) tap ).getDefaultFileSystemURIScheme( defaultJobConf ); } public URI getURIScheme( Tap tap ) { return ( (Hfs) tap ).getURIScheme( defaultJobConf ); } @Override protected Tap makeTempTap( String prefix, String name ) { return new TempHfs( defaultJobConf, Util.makePath( prefix, name ), intermediateSchemeClass, prefix == null ); } }